{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marco\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from src.utils import *\n",
    "from src.models.models import Model_Phrase_Concatenation, Model_Phrase_Extraction, Model_concat_nopooling\n",
    "from src.models.baseline import Baseline\n",
    "from datasets import concatenate_datasets\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import DefaultDataCollator, AutoTokenizer, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "set_seeds(RANDOM_SEED)\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory: c:\\Users\\marco\\OneDrive\\Immagini\\Documenti\\GitHub\\ediref\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>emotions</th>\n",
       "      <th>utterances</th>\n",
       "      <th>triggers</th>\n",
       "      <th>emotions_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>utterance_0</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
       "      <td>[also I was the point person on my company's t...</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>utterance_1</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
       "      <td>[also I was the point person on my company's t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 3, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>utterance_2</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
       "      <td>[also I was the point person on my company's t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>utterance_3</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
       "      <td>[also I was the point person on my company's t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 4, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>utterance_4</td>\n",
       "      <td>[surprise, sadness, surprise, fear]</td>\n",
       "      <td>[But then who? The waitress I went out with la...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>[3, 6, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>utterance_3995</td>\n",
       "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
       "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[2, 1, 2, 2, 3, 5, 2, 5, 3, 2, 2, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>utterance_3996</td>\n",
       "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
       "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[2, 1, 2, 2, 3, 5, 2, 5, 3, 2, 2, 5, 5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>utterance_3997</td>\n",
       "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
       "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[2, 1, 2, 2, 3, 5, 2, 5, 3, 2, 2, 5, 5, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>utterance_3998</td>\n",
       "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
       "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[2, 1, 2, 2, 3, 5, 2, 5, 3, 2, 2, 5, 5, 2, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>utterance_3999</td>\n",
       "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
       "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 1, 2, 2, 3, 5, 2, 5, 3, 2, 2, 5, 5, 2, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             episode                                           emotions  \\\n",
       "0        utterance_0     [neutral, neutral, neutral, neutral, surprise]   \n",
       "1        utterance_1  [neutral, neutral, neutral, neutral, surprise,...   \n",
       "2        utterance_2  [neutral, neutral, neutral, neutral, surprise,...   \n",
       "3        utterance_3  [neutral, neutral, neutral, neutral, surprise,...   \n",
       "4        utterance_4                [surprise, sadness, surprise, fear]   \n",
       "...              ...                                                ...   \n",
       "3995  utterance_3995  [neutral, joy, neutral, neutral, surprise, dis...   \n",
       "3996  utterance_3996  [neutral, joy, neutral, neutral, surprise, dis...   \n",
       "3997  utterance_3997  [neutral, joy, neutral, neutral, surprise, dis...   \n",
       "3998  utterance_3998  [neutral, joy, neutral, neutral, surprise, dis...   \n",
       "3999  utterance_3999  [neutral, joy, neutral, neutral, surprise, dis...   \n",
       "\n",
       "                                             utterances  \\\n",
       "0     [also I was the point person on my company's t...   \n",
       "1     [also I was the point person on my company's t...   \n",
       "2     [also I was the point person on my company's t...   \n",
       "3     [also I was the point person on my company's t...   \n",
       "4     [But then who? The waitress I went out with la...   \n",
       "...                                                 ...   \n",
       "3995  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
       "3996  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
       "3997  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
       "3998  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
       "3999  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
       "\n",
       "                                               triggers  \\\n",
       "0                                       [0, 0, 0, 1, 0]   \n",
       "1                                 [0, 0, 0, 0, 0, 1, 0]   \n",
       "2                     [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
       "3               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
       "4                                          [0, 0, 1, 0]   \n",
       "...                                                 ...   \n",
       "3995               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "3996         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "3997      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
       "3998   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
       "3999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            emotions_id  \n",
       "0                                       [2, 2, 2, 2, 3]  \n",
       "1                                 [2, 2, 2, 2, 3, 2, 2]  \n",
       "2                     [2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 4]  \n",
       "3               [2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 4, 2, 3]  \n",
       "4                                          [3, 6, 3, 4]  \n",
       "...                                                 ...  \n",
       "3995               [2, 1, 2, 2, 3, 5, 2, 5, 3, 2, 2, 5]  \n",
       "3996         [2, 1, 2, 2, 3, 5, 2, 5, 3, 2, 2, 5, 5, 2]  \n",
       "3997      [2, 1, 2, 2, 3, 5, 2, 5, 3, 2, 2, 5, 5, 2, 2]  \n",
       "3998   [2, 1, 2, 2, 3, 5, 2, 5, 3, 2, 2, 5, 5, 2, 2, 3]  \n",
       "3999  [2, 1, 2, 2, 3, 5, 2, 5, 3, 2, 2, 5, 5, 2, 2, ...  \n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://drive.google.com/uc?export=download&id=1wVNU2XvvhqjaGXZM-JLJwOt97gt4g9j2\"\n",
    "dataset_name = \"MELD_train_efr.json\"\n",
    "\n",
    "df_manager = DataframeManager(url, dataset_name)\n",
    "\n",
    "df = df_manager.produce_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_card = 'bert-base-uncased'\n",
    "# model_card = 'roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
    "\n",
    "model_dir = \"./model_dir/\"+model_card+\"/\"\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tokenized, val_data_tokenized, test_data_tokenized = df_manager.produce_dataset(tokenizer, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pos_weight(data, labels_column, class_weights=True, factor=1):\n",
    "    y = data[labels_column].numpy()\n",
    "    if class_weights:\n",
    "        return torch.tensor(compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)).to(\"cuda\")\n",
    "    else:\n",
    "        return torch.tensor(compute_class_weight(class_weight=None, classes=np.unique(y), y=y)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelTrainer(Trainer):\n",
    "    def __init__(self, pos_weight=None, **kwargs):\n",
    "        self.emotions_pos_weight, self.triggers_pos_weight = pos_weight\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        emotions_true = inputs[\"emotions_id_one_hot_encoding\"].to(\"cuda\")\n",
    "        triggers_true = inputs[\"triggers\"].unsqueeze(1).float().to(\"cuda\")\n",
    "\n",
    "        result = model(**inputs)\n",
    "        \n",
    "        emotion_logits = result['emotion_logits'].to(\"cuda\")\n",
    "        trigger_logits = result['trigger_logits'].to(\"cuda\")\n",
    "        \n",
    "        loss_fct_emotions = torch.nn.CrossEntropyLoss(weight=self.emotions_pos_weight).to(\"cuda\")        \n",
    "        loss_fct_triggers = torch.nn.BCEWithLogitsLoss(pos_weight=self.triggers_pos_weight[1]).to(\"cuda\")\n",
    "\n",
    "        loss_emotions = loss_fct_emotions(emotion_logits, emotions_true.float())\n",
    "        loss_triggers = loss_fct_triggers(trigger_logits, triggers_true)\n",
    "\n",
    "        loss_emotions_wt = 0.5\n",
    "        loss_triggers_wt = 0.5\n",
    "\n",
    "        loss = loss_emotions_wt*loss_emotions + loss_triggers_wt*loss_triggers\n",
    "        return (loss, {'emotion_logits': emotion_logits, 'trigger_logits': trigger_logits}) if return_outputs else loss\n",
    "\n",
    "def get_trainer(model, train, val, model_dir, class_weights=True, batch_size=1, epochs=20):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=model_dir,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='u_avg_f1',\n",
    "        report_to='none',\n",
    "        label_names=[\"emotions_id\", \"triggers\", \"dialogue_index\"],\n",
    "    )\n",
    "\n",
    "    full_dataset = concatenate_datasets([train_data_tokenized, val_data_tokenized, test_data_tokenized])\n",
    "    pos_weight = (init_pos_weight(full_dataset, df_manager.column_emotions_id, class_weights), init_pos_weight(full_dataset, df_manager.column_triggers, class_weights))\n",
    "\n",
    "    trainer = MultiLabelTrainer(\n",
    "        pos_weight=pos_weight,\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train,\n",
    "        eval_dataset=val,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=lambda pred: compute_metrics(pred, len(df_manager.emotion2id.keys())),\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\datasets\\table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540945c1abb54e678f38980bea92e0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.023462644404346,\n",
       " 'eval_accuracy_emotions': 0.209,\n",
       " 'eval_accuracy_triggers': 0.8209,\n",
       " 'eval_u_avg_f1': 0.4422,\n",
       " 'eval_u_f1scores_emotions': 0.1308,\n",
       " 'eval_u_f1scores_triggers': 0.7537,\n",
       " 'eval_d_f1scores_emotions': 0.2149,\n",
       " 'eval_d_f1scores_triggers': 0.7526,\n",
       " 'eval_runtime': 13.4439,\n",
       " 'eval_samples_per_second': 4.984,\n",
       " 'eval_steps_per_second': 1.265}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to load a model\n",
    "b = Model_Phrase_Extraction(len(df_manager.unique_emotions), tokenizer.sep_token_id)\n",
    "model_path = model_dir + \"bert_extraction_51\"\n",
    "b.load_state_dict(torch.load(model_path+\"/bert_extraction_51.pth\"))\n",
    "tr = get_trainer(b, train_data_tokenized, val_data_tokenized, model_path, class_weights=True, batch_size=4, epochs=5)\n",
    "tr.evaluate(val_data_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_extr_model(seed):\n",
    "    set_seeds(seed)\n",
    "    base_model = Model_Phrase_Extraction(len(df_manager.unique_emotions))\n",
    "    model_path = model_dir+\"extraction_\"+str(seed)\n",
    "\n",
    "    trainer = get_trainer(base_model, train_data_tokenized, val_data_tokenized, model_path, class_weights=True, batch_size=4, epochs=5)\n",
    "\n",
    "    print(f'Training EXTRACTION MODEL with seed {seed}:')\n",
    "\n",
    "    trainer.train()\n",
    "    torch.save(base_model.state_dict(), model_path+\"/extraction_\"+str(seed)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [49, 666, 51, 77, 111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training model with seed 111\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_extr_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m111\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mtrain_extr_model\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_extr_model\u001b[39m(seed):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mset_seeds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     base_model \u001b[38;5;241m=\u001b[39m Model_Phrase_Extraction(\u001b[38;5;28mlen\u001b[39m(df_manager\u001b[38;5;241m.\u001b[39munique_emotions))\n\u001b[0;32m      4\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m model_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextraction_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(seed)\n",
      "File \u001b[1;32mc:\\Users\\marco\\OneDrive\\Immagini\\Documenti\\GitHub\\ediref\\src\\utils.py:15\u001b[0m, in \u001b[0;36mset_seeds\u001b[1;34m(SEED)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_seeds\u001b[39m(SEED):\n\u001b[0;32m     14\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(SEED)\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\torch\\random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[1;32m---> 40\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\torch\\cuda\\random.py:124\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m    121\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m    122\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m--> 124\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_call\u001b[1;34m(callable, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lazy_call\u001b[39m(callable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 229\u001b[0m         \u001b[43mcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\torch\\cuda\\random.py:122\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[1;34m()\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[0;32m    121\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m--> 122\u001b[0m     \u001b[43mdefault_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Training model with seed 111\n",
    "train_extr_model(111)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
