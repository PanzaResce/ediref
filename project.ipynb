{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tb6JkaXPQ8c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\marco\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch\n",
        "import urllib\n",
        "from src.utils import *\n",
        "from src.models.baseline import Baseline\n",
        "from torch import nn\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import f1_score, multilabel_confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, concatenate_datasets\n",
        "from tqdm import tqdm\n",
        "from transformers import BertLayer, AutoModelForSequenceClassification, DataCollatorWithPadding, AutoTokenizer, AutoConfig, TrainingArguments, Trainer, BertConfig, BertModel, BertPreTrainedModel, RobertaConfig, RobertaModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2MsBHCqQ8c_",
        "outputId": "4940d008-c6d5-494c-907a-8198446a460b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RANDOM_SEED = 42\n",
        "set_seeds(RANDOM_SEED)\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current work directory: d:\\shared\\unibo\\year2\\NLP\\assignments\\project\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>emotions</th>\n",
              "      <th>utterances</th>\n",
              "      <th>triggers</th>\n",
              "      <th>emotions_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 1, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utterance_1</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 0, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utterance_2</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utterance_3</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 5, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utterance_4</td>\n",
              "      <td>[surprise, sadness, surprise, fear]</td>\n",
              "      <td>[But then who? The waitress I went out with la...</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 6, 0, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>utterance_3995</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>[1, 2, 1, 1, 0, 4, 1, 4, 0, 1, 1, 4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>utterance_3996</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>[1, 2, 1, 1, 0, 4, 1, 4, 0, 1, 1, 4, 4, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>utterance_3997</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[1, 2, 1, 1, 0, 4, 1, 4, 0, 1, 1, 4, 4, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>utterance_3998</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[1, 2, 1, 1, 0, 4, 1, 4, 0, 1, 1, 4, 4, 1, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>utterance_3999</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 2, 1, 1, 0, 4, 1, 4, 0, 1, 1, 4, 4, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             episode                                           emotions  \\\n",
              "0        utterance_0     [neutral, neutral, neutral, neutral, surprise]   \n",
              "1        utterance_1  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "2        utterance_2  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "3        utterance_3  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "4        utterance_4                [surprise, sadness, surprise, fear]   \n",
              "...              ...                                                ...   \n",
              "3995  utterance_3995  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3996  utterance_3996  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3997  utterance_3997  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3998  utterance_3998  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3999  utterance_3999  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "\n",
              "                                             utterances  \\\n",
              "0     [also I was the point person on my company's t...   \n",
              "1     [also I was the point person on my company's t...   \n",
              "2     [also I was the point person on my company's t...   \n",
              "3     [also I was the point person on my company's t...   \n",
              "4     [But then who? The waitress I went out with la...   \n",
              "...                                                 ...   \n",
              "3995  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3996  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3997  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3998  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3999  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "\n",
              "                                               triggers  \\\n",
              "0                                       [0, 0, 0, 1, 0]   \n",
              "1                                 [0, 0, 0, 0, 0, 1, 0]   \n",
              "2                     [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
              "3               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
              "4                                          [0, 0, 1, 0]   \n",
              "...                                                 ...   \n",
              "3995               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
              "3996         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
              "3997      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
              "3998   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
              "3999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                            emotions_id  \n",
              "0                                       [1, 1, 1, 1, 0]  \n",
              "1                                 [1, 1, 1, 1, 0, 1, 1]  \n",
              "2                     [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 5]  \n",
              "3               [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 5, 1, 0]  \n",
              "4                                          [0, 6, 0, 5]  \n",
              "...                                                 ...  \n",
              "3995               [1, 2, 1, 1, 0, 4, 1, 4, 0, 1, 1, 4]  \n",
              "3996         [1, 2, 1, 1, 0, 4, 1, 4, 0, 1, 1, 4, 4, 1]  \n",
              "3997      [1, 2, 1, 1, 0, 4, 1, 4, 0, 1, 1, 4, 4, 1, 1]  \n",
              "3998   [1, 2, 1, 1, 0, 4, 1, 4, 0, 1, 1, 4, 4, 1, 1, 0]  \n",
              "3999  [1, 2, 1, 1, 0, 4, 1, 4, 0, 1, 1, 4, 4, 1, 1, ...  \n",
              "\n",
              "[4000 rows x 5 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = \"https://drive.google.com/uc?export=download&id=1wVNU2XvvhqjaGXZM-JLJwOt97gt4g9j2\"\n",
        "dataset_name = \"MELD_train_efr.json\"\n",
        "\n",
        "df_manager = DataframeManager(url, dataset_name)\n",
        "\n",
        "df = df_manager.produce_df()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aYeINdxlLlYW",
        "outputId": "08317111-0a25-4b78-eac1-f6609fa7ee4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3200, 5)\n",
            "(400, 5)\n",
            "(400, 5)\n"
          ]
        }
      ],
      "source": [
        "train_df, val_df, test_df = df_manager.split_df(RANDOM_SEED)\n",
        "print(train_df.shape)\n",
        "print(val_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "9TNd9SBUa60R",
        "outputId": "1ee58b4f-f7be-4347-8798-26bdcc1dd36c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_manager.plot_emotion_distribution(train_df, val_df, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fmi-B-roQ8dR"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pla-hCGKQ8dR",
        "outputId": "428d341c-d851-4780-9085-37dac51df287"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'episode': 'utterance_3176',\n",
              " 'emotions': ['fear',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'anger',\n",
              "  'neutral',\n",
              "  'sadness'],\n",
              " 'utterances': [\"I'm so sorry. Please, stop freaking out.\",\n",
              "  \"I'm not freaking out.\",\n",
              "  'Why would I be freaking out?',\n",
              "  'A woman named Heldi called and said we were getting married, but that happens everyday.',\n",
              "  'Honey, we were at this beautiful place, and I-I-I just put our names down for fun!',\n",
              "  \"I mean, what's the harm in that?\",\n",
              "  'Right here!'],\n",
              " 'triggers': [0, 0, 0, 1, 1, 1, 0],\n",
              " 'emotions_id': [6, 5, 5, 5, 2, 5, 1],\n",
              " '__index_level_0__': 3176}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[3070]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kOwxAe3qLlYZ"
      },
      "outputs": [],
      "source": [
        "model_card = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
        "\n",
        "model_dir = \"./model_dir/\"+model_card+\"/\"\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-UN6VqNKQ8dR",
        "outputId": "327af93c-801b-40fc-e9fc-49c93fad93ad"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4aa6341148b43c2bfa2596c8ce6900d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d0b4d1778bd43ebb3ff50373b000f49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b79004959bc452694144e0e93fa95ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'episode': 'utterance_3491', 'emotions': ['surprise', 'fear', 'surprise', 'sadness'], 'utterances': ['You-you\\x85you had sex with Ursula?!', 'Uh, a little bit. She-she-she walked in and I thought she was you and I kissed her and', \"You didn't notice she was wearing different clothes?!\", 'Well I was just so excited to see you.'], 'triggers': tensor([0, 0, 1, 0]), 'emotions_id': tensor([4, 6, 4, 1]), '__index_level_0__': tensor(3491), 'input_ids': tensor([[  101,  2017,  1011,  2017, 29337,  2018,  3348,  2007, 20449,  1029,\n",
            "           999,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0],\n",
            "        [  101,  7910,  1010,  1037,  2210,  2978,  1012,  2016,  1011,  2016,\n",
            "          1011,  2016,  2939,  1999,  1998,  1045,  2245,  2016,  2001,  2017,\n",
            "          1998,  1045,  4782,  2014,  1998,   102],\n",
            "        [  101,  2017,  2134,  1005,  1056,  5060,  2016,  2001,  4147,  2367,\n",
            "          4253,  1029,   999,   102,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0],\n",
            "        [  101,  2092,  1045,  2001,  2074,  2061,  7568,  2000,  2156,  2017,\n",
            "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0]])}\n"
          ]
        }
      ],
      "source": [
        "train_data_tokenised, val_data_set, test_data_set = get_datasets(train_dataset, val_dataset, test_dataset, tokenizer)\n",
        "print(train_data_tokenised[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJWSxdXFQ8dT"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OSNzNVyiLlYb"
      },
      "outputs": [],
      "source": [
        "seeds = [666, 55, 42]\n",
        "\n",
        "X = train_df['utterances']\n",
        "Y = train_df[['triggers', 'emotions_id']]\n",
        "seed_table = {'majority': {}, 'uniform': {},\n",
        "              'model_BERT': {}, 'model_BERT_Freezed': {}}\n",
        "random_clf = Baseline(\"uniform\", X, Y, id2emotion)\n",
        "majority_clf = Baseline(\"most_frequent\", X, Y, id2emotion)\n",
        "for seed in seeds:\n",
        "    seed_table[\"uniform\"][seed] = random_clf.score()\n",
        "    seed_table[\"majority\"][seed] = majority_clf.score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx520nvqLlYb",
        "outputId": "6c7d3294-88ee-44a5-c995-22a56d17676b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'majority': {666: {'accuracy': 0.6403,\n",
              "   'f1-score': {'accuracy_emotions': 0.4392,\n",
              "    'accuracy_triggers': 0.8415,\n",
              "    'f1scores_emotions_instance': 0.0814,\n",
              "    'f1scores_emotions_flatten': 0.0872,\n",
              "    'f1scores_triggers_instance': 0.4392,\n",
              "    'f1scores_triggers_flatten': 0.457}},\n",
              "  55: {'accuracy': 0.6403,\n",
              "   'f1-score': {'accuracy_emotions': 0.4392,\n",
              "    'accuracy_triggers': 0.8415,\n",
              "    'f1scores_emotions_instance': 0.0814,\n",
              "    'f1scores_emotions_flatten': 0.0872,\n",
              "    'f1scores_triggers_instance': 0.4392,\n",
              "    'f1scores_triggers_flatten': 0.457}},\n",
              "  42: {'accuracy': 0.6403,\n",
              "   'f1-score': {'accuracy_emotions': 0.4392,\n",
              "    'accuracy_triggers': 0.8415,\n",
              "    'f1scores_emotions_instance': 0.0814,\n",
              "    'f1scores_emotions_flatten': 0.0872,\n",
              "    'f1scores_triggers_instance': 0.4392,\n",
              "    'f1scores_triggers_flatten': 0.457}}},\n",
              " 'uniform': {666: {'accuracy': 0.3233,\n",
              "   'f1-score': {'accuracy_emotions': 0.1405,\n",
              "    'accuracy_triggers': 0.5015,\n",
              "    'f1scores_emotions_instance': 0.0704,\n",
              "    'f1scores_emotions_flatten': 0.1166,\n",
              "    'f1scores_triggers_instance': 0.4125,\n",
              "    'f1scores_triggers_flatten': 0.4347}},\n",
              "  55: {'accuracy': 0.3254,\n",
              "   'f1-score': {'accuracy_emotions': 0.1461,\n",
              "    'accuracy_triggers': 0.5016,\n",
              "    'f1scores_emotions_instance': 0.0733,\n",
              "    'f1scores_emotions_flatten': 0.1222,\n",
              "    'f1scores_triggers_instance': 0.4105,\n",
              "    'f1scores_triggers_flatten': 0.4338}},\n",
              "  42: {'accuracy': 0.3219,\n",
              "   'f1-score': {'accuracy_emotions': 0.1448,\n",
              "    'accuracy_triggers': 0.5016,\n",
              "    'f1scores_emotions_instance': 0.0727,\n",
              "    'f1scores_emotions_flatten': 0.1219,\n",
              "    'f1scores_triggers_instance': 0.4105,\n",
              "    'f1scores_triggers_flatten': 0.4345}}},\n",
              " 'model_BERT': {},\n",
              " 'model_BERT_Freezed': {}}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wTA_dWYFLlYb"
      },
      "outputs": [],
      "source": [
        "def init_pos_weight(data, labels, class_weights=True, factor=1):\n",
        "    if class_weights:\n",
        "        pos_weight = list()\n",
        "        emotions_counts = {label:0 for label in unique_emotions}\n",
        "        for sentance_emotions in data[column_emotions]:\n",
        "            for emotion in sentance_emotions:\n",
        "                emotions_counts[emotion] = emotions_counts[emotion] + 1\n",
        "        sum_of_all_emotions = sum(emotions_counts.values())\n",
        "        for label in labels:\n",
        "            w = (sum_of_all_emotions-emotions_counts[label])/emotions_counts[label]   # num_neg/num_pos for each class as specified in the documentation for BCEWithLogitsLoss\n",
        "            if w > 1:                       # increase recall of minority classes\n",
        "                w*=factor                   # factor to magnify the weight (not standard)\n",
        "                pos_weight.append(w)\n",
        "            else:\n",
        "                pos_weight.append(1)        # non minority classes are not influenced (pos_weight = 1)\n",
        "        return torch.tensor(pos_weight).to(\"cuda\")\n",
        "    else:\n",
        "        return torch.ones([len(labels)]).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ztKhP1pmLlYc"
      },
      "outputs": [],
      "source": [
        "class MultiLabelTrainer(Trainer):\n",
        "    def __init__(self, pos_weight, **kwargs):\n",
        "        self.pos_weight = pos_weight\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        emotions_true = inputs.get(\"emotions_id\")\n",
        "        triggers_true = inputs.get(\"triggers\")\n",
        "        emotion_outputs, triggers_outputs = model(**inputs)\n",
        "        emotion_logits, triggers_logits = emotion_outputs.logits, triggers_outputs.logits\n",
        "        loss_fct = torch.nn.BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
        "        loss_emotions = loss_fct(emotion_logits, emotions_true)\n",
        "        loss_triggers = loss_fct(triggers_logits, triggers_true)\n",
        "        loss = loss_emotions + loss_triggers\n",
        "        return (loss, {'emotion_outputs': emotion_outputs, 'triggers_outputs': triggers_outputs}) if return_outputs else loss\n",
        "\n",
        "\n",
        "def get_trainer(model, train, val, model_dir, class_weights=True, batch_size=1, epochs=20):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=model_dir,\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=0.01,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        lr_scheduler_type=\"cosine_with_restarts\",\n",
        "        save_total_limit = 1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='macro-avg-f1score',\n",
        "        report_to='none'\n",
        "    )\n",
        "\n",
        "    pos_weight = init_pos_weight(concatenate_datasets([train_dataset, val_dataset, test_dataset]), emotion2id.keys(), class_weights)\n",
        "\n",
        "    trainer = MultiLabelTrainer(\n",
        "        pos_weight=pos_weight,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train,\n",
        "        eval_dataset=val,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=lambda pred: compute_metrics(pred),\n",
        "    )\n",
        "\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Y0haz8zYLlYc"
      },
      "outputs": [],
      "source": [
        "class BERT_Model(BertPreTrainedModel):\n",
        "    def __init__(self, load=None, pos_weight=None, freeze=False):\n",
        "        self.config = BertConfig.from_pretrained(model_card, output_attentions=True, output_hidden_states=True)\n",
        "        self.freeze = freeze\n",
        "\n",
        "        super().__init__(self.config)\n",
        "        self.core = self.initialize_model(load)\n",
        "        # Freeze BERT embedding layer parameters\n",
        "        if freeze:\n",
        "            for param in self.core.embeddings.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if pos_weight == None:\n",
        "            self.pos_weight = torch.ones([self.config.num_labels]).to(\"cuda\")\n",
        "        else:\n",
        "            self.pos_weight = pos_weight\n",
        "        self.emotion_head = nn.Linear(self.config.hidden_size, len(unique_emotions))\n",
        "        self.trigger_head = nn.Linear(self.config.hidden_size, 2)\n",
        "        self.post_init()\n",
        "\n",
        "    def initialize_model(self, load):\n",
        "        if load == None:\n",
        "            return BertModel(self.config)\n",
        "        else:\n",
        "            print(load)\n",
        "            return BertModel.from_pretrained(load, config=load+'/config.json', local_files_only=True)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        emotions_true=None,\n",
        "        triggers_true=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        \n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "        outputs = self.core(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = outputs[0]\n",
        "        # print(\"Sequence Input Shape:\", input_ids.shape)\n",
        "        # print(\"Sequence Output Shape:\", outputs.shape)\n",
        "        # print(\"Sequence Output:\", outputs)\n",
        "        emotion_logits = self.emotion_head(sequence_output)\n",
        "        trigger_logits = self.trigger_head(sequence_output)\n",
        "\n",
        "        loss = None\n",
        "        if emotions_true is not None and triggers_true is not None:\n",
        "            loss_emotions = loss_fct(emotion_logits, emotions_true)\n",
        "            loss_triggers = loss_fct(trigger_logits, triggers_true)\n",
        "            loss = loss_emotions + loss_triggers\n",
        "\n",
        "        return {\"loss\": loss,\n",
        "                \"emotion_logits\": emotion_logits,\n",
        "                \"trigger_logits\": trigger_logits,\n",
        "                \"outputs\": outputs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Forward pass example - execute before initializing trainer\n",
        "model_B = BERT_Model()\n",
        "\n",
        "outputs = model_B(input_ids = train_data_tokenised[0][\"input_ids\"][0].unsqueeze(0), attention_mask=train_data_tokenised[0][\"attention_mask\"][0].unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 34, 768])\n",
            "torch.Size([1, 768])\n"
          ]
        }
      ],
      "source": [
        "print(outputs[\"outputs\"][0].shape)\n",
        "print(outputs[\"outputs\"][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 34, 768])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs[\"outputs\"][2][1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'episode': 'utterance_527',\n",
              " 'emotions': ['fear', 'neutral', 'anger', 'sadness'],\n",
              " 'utterances': [\"Oh my God! Oh my God! I'm so sorry!\",\n",
              "  \"Aw forget it, it's from\",\n",
              "  \"You think you can knock up my daughter and then not marry her?! I'm gonna kill you!!\",\n",
              "  \"Y'know this is actually not a great time for me.\"],\n",
              " 'triggers': tensor([0, 0, 1, 0]),\n",
              " 'emotions_id': tensor([2, 0, 3, 6]),\n",
              " '__index_level_0__': tensor(527),\n",
              " 'input_ids': tensor([[  101,  2821,  2026,  2643,   999,  2821,  2026,  2643,   999,  1045,\n",
              "           1005,  1049,  2061,  3374,   999,   102,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0],\n",
              "         [  101, 22091,  5293,  2009,  1010,  2009,  1005,  1055,  2013,   102,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0],\n",
              "         [  101,  2017,  2228,  2017,  2064,  7324,  2039,  2026,  2684,  1998,\n",
              "           2059,  2025,  5914,  2014,  1029,   999,  1045,  1005,  1049,  6069,\n",
              "           3102,  2017,   999,   999,   102],\n",
              "         [  101,  1061,  1005,  2113,  2023,  2003,  2941,  2025,  1037,  2307,\n",
              "           2051,  2005,  2033,  1012,   102,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0]]),\n",
              " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0]])}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_tokenised[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "0FNnputQLlYc",
        "outputId": "a24d3ea2-5984-4c53-b455-c97f8224d9f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\datasets\\table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
            "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training BASE_MODEL with seed 666:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b314499c34ec447fa585dffaad65d023",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/400 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "ValueError",
          "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:748\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[1;32m--> 748\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:720\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[1;34m(value, dtype)\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(value))\n\u001b[1;32m--> 720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mTypeError\u001b[0m: not a sequence",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create trainer for Conclusion+Premises\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# trainer_freezed = get_trainer(base_model_freezed, train_dataset, val_dataset, model_dir+\"baseline_freezed\", class_weights=True, batch_size=1, epochs=10)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining BASE_MODEL with seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1821\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1818\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1820\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1821\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   1822\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\data_loader.py:451\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\data\\data_collator.py:249\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m--> 249\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[0;32m    257\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3299\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[1;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[0;32m   3296\u001b[0m             batch_outputs[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3297\u001b[0m         batch_outputs[key]\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[1;32m-> 3299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:223\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[1;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[0;32m    219\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[1;32m--> 223\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:764\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    760\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    761\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    762\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    763\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    765\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    766\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    767\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    768\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    769\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[1;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
          ]
        }
      ],
      "source": [
        "seeds = [666]\n",
        "for seed in seeds:\n",
        "        set_seeds(seed)\n",
        "        base_model = BERT_Model()\n",
        "        # base_model_freezed = BERT_Model(freeze=True)\n",
        "\n",
        "        # Create trainer for Conclusion only\n",
        "        trainer = get_trainer(base_model, train_data_tokenised, val_data_set, model_dir+\"baseline\", class_weights=True, batch_size=8, epochs=1)\n",
        "\n",
        "        # Create trainer for Conclusion+Premises\n",
        "        # trainer_freezed = get_trainer(base_model_freezed, train_dataset, val_dataset, model_dir+\"baseline_freezed\", class_weights=True, batch_size=1, epochs=10)\n",
        "\n",
        "        print(f'Training BASE_MODEL with seed {seed}:')\n",
        "        trainer.train()\n",
        "\n",
        "        #print(f'Training BASE_MODEL_FREEZED with seed {seed}:')\n",
        "        #trainer_freezed.train()\n",
        "\n",
        "        #test_prediction_info = trainer.predict(dataset)\n",
        "        #test_predictions, test_labels = test_prediction_info.predictions, test_prediction_info.label_ids\n",
        "        #test_metrics.append(compute_metrics([test_predictions, test_labels], list(level_2.keys())))\n",
        "#\n",
        "        ## fill seed table\n",
        "        #seed_table[\"model_BERT\"][seed] = test_bert\n",
        "        #seed_table[\"model_BERT_Freezed\"][seed] = test_CP"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
