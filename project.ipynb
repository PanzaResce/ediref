{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install transformers[torch]\n",
        "# !pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tb6JkaXPQ8c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\marco\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from src.utils import *\n",
        "from src.models.baseline import Baseline\n",
        "from src.models.models import *\n",
        "from datasets import concatenate_datasets\n",
        "from transformers import DefaultDataCollator, AutoTokenizer, TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2MsBHCqQ8c_",
        "outputId": "4940d008-c6d5-494c-907a-8198446a460b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.0+cu121\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "RANDOM_SEED = 42\n",
        "set_seeds(RANDOM_SEED)\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current work directory: c:\\Users\\marco\\OneDrive\\Immagini\\Documenti\\GitHub\\ediref\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>emotions</th>\n",
              "      <th>utterances</th>\n",
              "      <th>triggers</th>\n",
              "      <th>emotions_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 1, 0]</td>\n",
              "      <td>[6, 6, 6, 6, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utterance_1</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[6, 6, 6, 6, 2, 6, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utterance_2</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>[6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utterance_3</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 3, 6, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utterance_4</td>\n",
              "      <td>[surprise, sadness, surprise, fear]</td>\n",
              "      <td>[But then who? The waitress I went out with la...</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[2, 5, 2, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>utterance_3995</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>[6, 1, 6, 6, 2, 4, 6, 4, 2, 6, 6, 4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>utterance_3996</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>[6, 1, 6, 6, 2, 4, 6, 4, 2, 6, 6, 4, 4, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>utterance_3997</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[6, 1, 6, 6, 2, 4, 6, 4, 2, 6, 6, 4, 4, 6, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>utterance_3998</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[6, 1, 6, 6, 2, 4, 6, 4, 2, 6, 6, 4, 4, 6, 6, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>utterance_3999</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[6, 1, 6, 6, 2, 4, 6, 4, 2, 6, 6, 4, 4, 6, 6, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             episode                                           emotions  \\\n",
              "0        utterance_0     [neutral, neutral, neutral, neutral, surprise]   \n",
              "1        utterance_1  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "2        utterance_2  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "3        utterance_3  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "4        utterance_4                [surprise, sadness, surprise, fear]   \n",
              "...              ...                                                ...   \n",
              "3995  utterance_3995  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3996  utterance_3996  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3997  utterance_3997  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3998  utterance_3998  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3999  utterance_3999  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "\n",
              "                                             utterances  \\\n",
              "0     [also I was the point person on my company's t...   \n",
              "1     [also I was the point person on my company's t...   \n",
              "2     [also I was the point person on my company's t...   \n",
              "3     [also I was the point person on my company's t...   \n",
              "4     [But then who? The waitress I went out with la...   \n",
              "...                                                 ...   \n",
              "3995  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3996  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3997  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3998  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3999  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "\n",
              "                                               triggers  \\\n",
              "0                                       [0, 0, 0, 1, 0]   \n",
              "1                                 [0, 0, 0, 0, 0, 1, 0]   \n",
              "2                     [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
              "3               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
              "4                                          [0, 0, 1, 0]   \n",
              "...                                                 ...   \n",
              "3995               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
              "3996         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
              "3997      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
              "3998   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
              "3999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                            emotions_id  \n",
              "0                                       [6, 6, 6, 6, 2]  \n",
              "1                                 [6, 6, 6, 6, 2, 6, 6]  \n",
              "2                     [6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 3]  \n",
              "3               [6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 3, 6, 2]  \n",
              "4                                          [2, 5, 2, 3]  \n",
              "...                                                 ...  \n",
              "3995               [6, 1, 6, 6, 2, 4, 6, 4, 2, 6, 6, 4]  \n",
              "3996         [6, 1, 6, 6, 2, 4, 6, 4, 2, 6, 6, 4, 4, 6]  \n",
              "3997      [6, 1, 6, 6, 2, 4, 6, 4, 2, 6, 6, 4, 4, 6, 6]  \n",
              "3998   [6, 1, 6, 6, 2, 4, 6, 4, 2, 6, 6, 4, 4, 6, 6, 2]  \n",
              "3999  [6, 1, 6, 6, 2, 4, 6, 4, 2, 6, 6, 4, 4, 6, 6, ...  \n",
              "\n",
              "[4000 rows x 5 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = \"https://drive.google.com/uc?export=download&id=1wVNU2XvvhqjaGXZM-JLJwOt97gt4g9j2\"\n",
        "dataset_name = \"MELD_train_efr.json\"\n",
        "\n",
        "df_manager = DataframeManager(url, dataset_name)\n",
        "\n",
        "df = df_manager.produce_df()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aYeINdxlLlYW",
        "outputId": "08317111-0a25-4b78-eac1-f6609fa7ee4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3200, 5)\n",
            "(400, 5)\n",
            "(400, 5)\n"
          ]
        }
      ],
      "source": [
        "train_df, val_df, test_df = df_manager.split_df(RANDOM_SEED)\n",
        "print(train_df.shape)\n",
        "print(val_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "9TNd9SBUa60R",
        "outputId": "1ee58b4f-f7be-4347-8798-26bdcc1dd36c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_manager.plot_emotion_distribution(train_df, val_df, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kOwxAe3qLlYZ"
      },
      "outputs": [],
      "source": [
        "model_card = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
        "\n",
        "model_dir = \"./model_dir/\"+model_card+\"/\"\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-UN6VqNKQ8dR",
        "outputId": "327af93c-801b-40fc-e9fc-49c93fad93ad"
      },
      "outputs": [],
      "source": [
        "train_data_tokenized, val_data_tokenized, test_data_tokenized = df_manager.produce_dataset(tokenizer, RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# num_el = 0\n",
        "# for el in train_dataset:\n",
        "#     num_el = num_el + len(el['utterances'])\n",
        "# print(num_el)\n",
        "# num_el = 0\n",
        "# for el in val_dataset:\n",
        "#     num_el = num_el + len(el['utterances'])\n",
        "# print(num_el)\n",
        "# num_el = 0\n",
        "# for el in test_dataset:\n",
        "#     num_el = num_el + len(el['utterances'])\n",
        "# print(num_el)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJWSxdXFQ8dT"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OSNzNVyiLlYb"
      },
      "outputs": [],
      "source": [
        "seeds = [666, 55, 42]\n",
        "\n",
        "X = train_df['utterances']\n",
        "Y = train_df[['triggers', 'emotions_id']]\n",
        "seed_table = {'majority': {}, 'uniform': {},\n",
        "              'model_BERT': {}, 'model_BERT_Freezed': {}}\n",
        "\n",
        "id2emotion = df_manager.get_id2emotion()\n",
        "random_clf = Baseline(\"uniform\", X, Y, id2emotion)\n",
        "majority_clf = Baseline(\"most_frequent\", X, Y, id2emotion)\n",
        "for seed in seeds:\n",
        "    seed_table[\"uniform\"][seed] = random_clf.score()\n",
        "    seed_table[\"majority\"][seed] = majority_clf.score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wTA_dWYFLlYb"
      },
      "outputs": [],
      "source": [
        "def init_pos_weight(data, labels, class_weights=True, factor=1):\n",
        "    if class_weights:\n",
        "        pos_weight = list()\n",
        "        emotions_counts = {label:0 for label in df_manager.unique_emotions}\n",
        "        for sentence_emotions in data[df_manager.column_emotions_id]:\n",
        "            for emotion in sentence_emotions:\n",
        "                emotions_counts[emotion] = emotions_counts[emotion] + 1\n",
        "        sum_of_all_emotions = sum(emotions_counts.values())\n",
        "        for label in labels:\n",
        "            w = (sum_of_all_emotions-emotions_counts[label])/emotions_counts[label]   # num_neg/num_pos for each class as specified in the documentation for BCEWithLogitsLoss\n",
        "            if w > 1:                       # increase recall of minority classes\n",
        "                w*=factor                   # factor to magnify the weight (not standard)\n",
        "                pos_weight.append(w)\n",
        "            else:\n",
        "                pos_weight.append(1)        # non minority classes are not influenced (pos_weight = 1)\n",
        "        return torch.tensor(pos_weight).to(\"cuda\")\n",
        "    else:\n",
        "        return torch.ones([len(labels)]).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ztKhP1pmLlYc"
      },
      "outputs": [],
      "source": [
        "class MultiLabelTrainer(Trainer):\n",
        "    def __init__(self, pos_weight, **kwargs):\n",
        "        self.pos_weight = pos_weight\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        emotions_true = inputs[\"emotions_id\"].to(\"cuda\")\n",
        "        triggers_true = inputs[\"triggers\"].float().unsqueeze(-1).to(\"cuda\")\n",
        "\n",
        "        result = model(**inputs)\n",
        "        \n",
        "        emotion_logits = result['emotion_logits'].to(\"cuda\")\n",
        "        trigger_logits = result['trigger_logits'].to(\"cuda\")\n",
        "        \n",
        "        loss_fct_emotions = torch.nn.BCEWithLogitsLoss(pos_weight=self.pos_weight)        \n",
        "        loss_fct_triggers = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "        loss_triggers = loss_fct_triggers(trigger_logits, triggers_true)\n",
        "        loss_emotions = loss_fct_emotions(emotion_logits, emotions_true.float())\n",
        "\n",
        "        loss = loss_emotions + loss_triggers\n",
        "        return (loss, {'emotion_logits': emotion_logits, 'trigger_logits': trigger_logits}) if return_outputs else loss\n",
        "\n",
        "    #def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval):\n",
        "    #    # Your existing implementation\n",
        "    #    \n",
        "    #    # Print the contents of the metrics dictionary\n",
        "    #    print(\"Metrics dictionary:\", metrics)\n",
        "    #\n",
        "    #    # Your existing implementation\n",
        "\n",
        "def get_trainer(model, train, val, model_dir, class_weights=True, batch_size=1, epochs=20):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=model_dir,\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=0.01,\n",
        "        save_strategy=\"epoch\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        lr_scheduler_type=\"cosine_with_restarts\",\n",
        "        save_total_limit = 1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='accuracy_emotions',\n",
        "        report_to='none'\n",
        "    )\n",
        "    # pos_weight = init_pos_weight(concatenate_datasets([train_data_tokenized, val_data_tokenized, test_data_tokenized]), df_manager.emotion2id.keys(), class_weights)\n",
        "    pos_weight = init_pos_weight(concatenate_datasets([train_data_tokenized, val_data_tokenized, test_data_tokenized]), df_manager.emotion2id.keys(), False)\n",
        "    trainer = MultiLabelTrainer(\n",
        "        pos_weight=pos_weight,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train,\n",
        "        eval_dataset=val,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=lambda pred: compute_metrics(pred, df_manager.get_id2emotion()),\n",
        "    )\n",
        "\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_B = BERT_Model_Phrase_Concatenation(df_manager)\n",
        "# def try_model_Concatenation(batch_start, batch_end):\n",
        "#         outputs_text = model_B(utterance_ids=train_data_tokenized[batch_start:batch_end]['utterance_ids'],\n",
        "#                 utterance_mask=train_data_tokenized[batch_start:batch_end]['utterance_mask'],\n",
        "#                 dialogue_ids=train_data_tokenized[batch_start:batch_end]['dialogue_ids'],\n",
        "#                 dialogue_mask=train_data_tokenized[batch_start:batch_end]['dialogue_mask'],\n",
        "#                 token_type_ids=None)\n",
        "#         return outputs_text\n",
        "# outputs_text = try_model_Concatenation(0, 30)\n",
        "# print(outputs_text['emotion_logits'].shape)\n",
        "# print(outputs_text['trigger_logits'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0FNnputQLlYc",
        "outputId": "a24d3ea2-5984-4c53-b455-c97f8224d9f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\datasets\\table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
            "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n",
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training BASE_MODEL with seed 666:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd1ebd9c972245d8b38a56b5890d272a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/53 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1652a68a45d945b7876d8cb2083b51e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Checkpoint destination directory ./model_dir/bert-base-uncased/baseline\\checkpoint-53 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_runtime': 4.4634, 'eval_samples_per_second': 15.011, 'eval_steps_per_second': 2.016, 'epoch': 1.0}\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'eval_accuracy_emotions'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining BASE_MODEL with seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#trainer.evaluate(val_data_tokenized[0])\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 1929\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[0;32m   1933\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:2274\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m-> 2274\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:2363\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[1;34m(self, model, trial, metrics)\u001b[0m\n\u001b[0;32m   2361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m metric_to_check\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2362\u001b[0m     metric_to_check \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_to_check\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2363\u001b[0m metric_value \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_to_check\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2365\u001b[0m operator \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgreater \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgreater_is_better \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mless\n\u001b[0;32m   2366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_metric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2368\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_model_checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2369\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m operator(metric_value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_metric)\n\u001b[0;32m   2370\u001b[0m ):\n",
            "\u001b[1;31mKeyError\u001b[0m: 'eval_accuracy_emotions'"
          ]
        }
      ],
      "source": [
        "seeds = [666]\n",
        "for seed in seeds:\n",
        "        set_seeds(seed)\n",
        "        base_model = BERT_Model_Phrase_Concatenation(df_manager)\n",
        "        # base_model_freezed = BERT_Model(freeze=True)\n",
        "\n",
        "        trainer = get_trainer(base_model, train_data_tokenized, val_data_tokenized, model_dir+\"baseline\", class_weights=True, batch_size=8, epochs=1)\n",
        "\n",
        "        # trainer_freezed = get_trainer(base_model_freezed, train_dataset, val_dataset, model_dir+\"baseline_freezed\", class_weights=True, batch_size=1, epochs=10)\n",
        "        print(f'Training BASE_MODEL with seed {seed}:')\n",
        "        #trainer.evaluate(val_data_tokenized[0])\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        #print(f'Training BASE_MODEL_FREEZED with seed {seed}:')\n",
        "        #trainer_freezed.train()\n",
        "\n",
        "        #test_prediction_info = trainer.predict(dataset)\n",
        "        #test_predictions, test_labels = test_prediction_info.predictions, test_prediction_info.label_ids\n",
        "        #test_metrics.append(compute_metrics([test_predictions, test_labels], list(level_2.keys())))\n",
        "\n",
        "        ## fill seed table\n",
        "        #seed_table[\"model_BERT\"][seed] = test_bert\n",
        "        #seed_table[\"model_BERT_Freezed\"][seed] = test_CP"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
