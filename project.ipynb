{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Requirement already satisfied: datasets in c:\\users\\marco\\anaconda3\\lib\\site-packages (2.13.2)\n",
            "Requirement already satisfied: xxhash in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (14.0.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (1.26.2)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (2023.12.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.1)\n",
            "Collecting charset-normalizer<3.0,>=2.0\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.6.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->datasets) (4.9.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\marco\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: colorama in c:\\users\\marco\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: charset-normalizer\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\marco\\\\anaconda3\\\\Lib\\\\site-packages\\\\~harset_normalizer\\\\md.cp39-win_amd64.pyd'\n",
            "Consider using the `--user` option or check the permissions.\n",
            "\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers[torch] in c:\\users\\marco\\anaconda3\\lib\\site-packages (4.36.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\marco\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: requests in c:\\users\\marco\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.19.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.26.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from transformers[torch]) (2023.10.3)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.1.0+cu121)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.24.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\marco\\anaconda3\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.12.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.11.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\marco\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.7.1)\n",
            "Requirement already satisfied: sympy in c:\\users\\marco\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.10.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\marco\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (1.26.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.2.1)\n",
            "Requirement already satisfied: accelerate in c:\\users\\marco\\anaconda3\\lib\\site-packages (0.24.1)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.0-py3-none-any.whl (297 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from accelerate) (1.26.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\marco\\anaconda3\\lib\\site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in c:\\users\\marco\\anaconda3\\lib\\site-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\marco\\anaconda3\\lib\\site-packages (from accelerate) (5.8.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\marco\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\marco\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\marco\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: sympy in c:\\users\\marco\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.10.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\marco\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2.11.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: requests in c:\\users\\marco\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\marco\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.2.1)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.24.1\n",
            "    Uninstalling accelerate-0.24.1:\n",
            "      Successfully uninstalled accelerate-0.24.1\n",
            "Successfully installed accelerate-0.29.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\marco\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "# !pip install datasets\n",
        "# !pip install transformers[torch]\n",
        "# !pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tb6JkaXPQ8c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\marco\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch\n",
        "import urllib\n",
        "from src.utils import *\n",
        "from src.models.baseline import Baseline\n",
        "from torch import nn\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import f1_score, multilabel_confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, concatenate_datasets\n",
        "from tqdm import tqdm\n",
        "from transformers import BertLayer, AutoModelForSequenceClassification, DataCollatorWithPadding, AutoTokenizer, AutoConfig, TrainingArguments, Trainer, BertConfig, BertModel, BertPreTrainedModel, RobertaConfig, RobertaModel;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2MsBHCqQ8c_",
        "outputId": "4940d008-c6d5-494c-907a-8198446a460b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.0+cu121\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "RANDOM_SEED = 42\n",
        "set_seeds(RANDOM_SEED)\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current work directory: c:\\Users\\marco\\OneDrive\\Immagini\\Documenti\\GitHub\\ediref\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>emotions</th>\n",
              "      <th>utterances</th>\n",
              "      <th>triggers</th>\n",
              "      <th>emotions_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utterance_1</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 3, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utterance_2</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utterance_3</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utterance_4</td>\n",
              "      <td>[surprise, sadness, surprise, fear]</td>\n",
              "      <td>[But then who? The waitress I went out with la...</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[3, 2, 3, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>utterance_3995</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>[0, 6, 0, 0, 3, 5, 0, 5, 3, 0, 0, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>utterance_3996</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>[0, 6, 0, 0, 3, 5, 0, 5, 3, 0, 0, 5, 5, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>utterance_3997</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[0, 6, 0, 0, 3, 5, 0, 5, 3, 0, 0, 5, 5, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>utterance_3998</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[0, 6, 0, 0, 3, 5, 0, 5, 3, 0, 0, 5, 5, 0, 0, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>utterance_3999</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 6, 0, 0, 3, 5, 0, 5, 3, 0, 0, 5, 5, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             episode                                           emotions  \\\n",
              "0        utterance_0     [neutral, neutral, neutral, neutral, surprise]   \n",
              "1        utterance_1  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "2        utterance_2  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "3        utterance_3  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "4        utterance_4                [surprise, sadness, surprise, fear]   \n",
              "...              ...                                                ...   \n",
              "3995  utterance_3995  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3996  utterance_3996  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3997  utterance_3997  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3998  utterance_3998  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3999  utterance_3999  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "\n",
              "                                             utterances  \\\n",
              "0     [also I was the point person on my company's t...   \n",
              "1     [also I was the point person on my company's t...   \n",
              "2     [also I was the point person on my company's t...   \n",
              "3     [also I was the point person on my company's t...   \n",
              "4     [But then who? The waitress I went out with la...   \n",
              "...                                                 ...   \n",
              "3995  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3996  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3997  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3998  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3999  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "\n",
              "                                               triggers  \\\n",
              "0                                       [0, 0, 0, 1, 0]   \n",
              "1                                 [0, 0, 0, 0, 0, 1, 0]   \n",
              "2                     [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
              "3               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
              "4                                          [0, 0, 1, 0]   \n",
              "...                                                 ...   \n",
              "3995               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
              "3996         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
              "3997      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
              "3998   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
              "3999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                            emotions_id  \n",
              "0                                       [0, 0, 0, 0, 3]  \n",
              "1                                 [0, 0, 0, 0, 3, 0, 0]  \n",
              "2                     [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1]  \n",
              "3               [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 3]  \n",
              "4                                          [3, 2, 3, 1]  \n",
              "...                                                 ...  \n",
              "3995               [0, 6, 0, 0, 3, 5, 0, 5, 3, 0, 0, 5]  \n",
              "3996         [0, 6, 0, 0, 3, 5, 0, 5, 3, 0, 0, 5, 5, 0]  \n",
              "3997      [0, 6, 0, 0, 3, 5, 0, 5, 3, 0, 0, 5, 5, 0, 0]  \n",
              "3998   [0, 6, 0, 0, 3, 5, 0, 5, 3, 0, 0, 5, 5, 0, 0, 3]  \n",
              "3999  [0, 6, 0, 0, 3, 5, 0, 5, 3, 0, 0, 5, 5, 0, 0, ...  \n",
              "\n",
              "[4000 rows x 5 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = \"https://drive.google.com/uc?export=download&id=1wVNU2XvvhqjaGXZM-JLJwOt97gt4g9j2\"\n",
        "dataset_name = \"MELD_train_efr.json\"\n",
        "\n",
        "df_manager = DataframeManager(url, dataset_name)\n",
        "\n",
        "df = df_manager.produce_df()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aYeINdxlLlYW",
        "outputId": "08317111-0a25-4b78-eac1-f6609fa7ee4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3200, 5)\n",
            "(400, 5)\n",
            "(400, 5)\n"
          ]
        }
      ],
      "source": [
        "train_df, val_df, test_df = df_manager.split_df(RANDOM_SEED)\n",
        "print(train_df.shape)\n",
        "print(val_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "9TNd9SBUa60R",
        "outputId": "1ee58b4f-f7be-4347-8798-26bdcc1dd36c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_manager.plot_emotion_distribution(train_df, val_df, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kOwxAe3qLlYZ"
      },
      "outputs": [],
      "source": [
        "model_card = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
        "\n",
        "model_dir = \"./model_dir/\"+model_card+\"/\"\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-UN6VqNKQ8dR",
        "outputId": "327af93c-801b-40fc-e9fc-49c93fad93ad"
      },
      "outputs": [],
      "source": [
        "train_data_tokenized, val_data_tokenized, test_data_tokenized = df_manager.produce_dataset(tokenizer, RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28062\n",
            "3437\n",
            "3501\n"
          ]
        }
      ],
      "source": [
        "num_el = 0\n",
        "for el in train_dataset:\n",
        "    num_el = num_el + len(el['utterances'])\n",
        "print(num_el)\n",
        "num_el = 0\n",
        "for el in val_dataset:\n",
        "    num_el = num_el + len(el['utterances'])\n",
        "print(num_el)\n",
        "num_el = 0\n",
        "for el in test_dataset:\n",
        "    num_el = num_el + len(el['utterances'])\n",
        "print(num_el)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJWSxdXFQ8dT"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSNzNVyiLlYb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "compute_metrics was called\n",
            "compute_metrics was called\n",
            "compute_metrics was called\n",
            "compute_metrics was called\n",
            "compute_metrics was called\n",
            "compute_metrics was called\n"
          ]
        }
      ],
      "source": [
        "seeds = [666, 55, 42]\n",
        "\n",
        "X = train_df['utterances']\n",
        "Y = train_df[['triggers', 'emotions_id']]\n",
        "seed_table = {'majority': {}, 'uniform': {},\n",
        "              'model_BERT': {}, 'model_BERT_Freezed': {}}\n",
        "\n",
        "id2emotion = df_manager.get_id2emotion()\n",
        "random_clf = Baseline(\"uniform\", X, Y, id2emotion)\n",
        "majority_clf = Baseline(\"most_frequent\", X, Y, id2emotion)\n",
        "for seed in seeds:\n",
        "    seed_table[\"uniform\"][seed] = random_clf.score()\n",
        "    seed_table[\"majority\"][seed] = majority_clf.score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx520nvqLlYb",
        "outputId": "6c7d3294-88ee-44a5-c995-22a56d17676b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'majority': {666: {'accuracy': 0.6403,\n",
              "   'f1-score': {'accuracy_emotions': 0.4392,\n",
              "    'accuracy_triggers': 0.8415,\n",
              "    'f1scores_emotions_instance': 0.0814,\n",
              "    'f1scores_emotions_flatten': 0.0872,\n",
              "    'f1scores_triggers_instance': 0.4392,\n",
              "    'f1scores_triggers_flatten': 0.457}},\n",
              "  55: {'accuracy': 0.6403,\n",
              "   'f1-score': {'accuracy_emotions': 0.4392,\n",
              "    'accuracy_triggers': 0.8415,\n",
              "    'f1scores_emotions_instance': 0.0814,\n",
              "    'f1scores_emotions_flatten': 0.0872,\n",
              "    'f1scores_triggers_instance': 0.4392,\n",
              "    'f1scores_triggers_flatten': 0.457}},\n",
              "  42: {'accuracy': 0.6403,\n",
              "   'f1-score': {'accuracy_emotions': 0.4392,\n",
              "    'accuracy_triggers': 0.8415,\n",
              "    'f1scores_emotions_instance': 0.0814,\n",
              "    'f1scores_emotions_flatten': 0.0872,\n",
              "    'f1scores_triggers_instance': 0.4392,\n",
              "    'f1scores_triggers_flatten': 0.457}}},\n",
              " 'uniform': {666: {'accuracy': 0.3197,\n",
              "   'f1-score': {'accuracy_emotions': 0.1458,\n",
              "    'accuracy_triggers': 0.5006,\n",
              "    'f1scores_emotions_instance': 0.0734,\n",
              "    'f1scores_emotions_flatten': 0.1225,\n",
              "    'f1scores_triggers_instance': 0.4092,\n",
              "    'f1scores_triggers_flatten': 0.4348}},\n",
              "  55: {'accuracy': 0.3203,\n",
              "   'f1-score': {'accuracy_emotions': 0.143,\n",
              "    'accuracy_triggers': 0.5036,\n",
              "    'f1scores_emotions_instance': 0.0724,\n",
              "    'f1scores_emotions_flatten': 0.1197,\n",
              "    'f1scores_triggers_instance': 0.4126,\n",
              "    'f1scores_triggers_flatten': 0.4367}},\n",
              "  42: {'accuracy': 0.321,\n",
              "   'f1-score': {'accuracy_emotions': 0.1445,\n",
              "    'accuracy_triggers': 0.4971,\n",
              "    'f1scores_emotions_instance': 0.0724,\n",
              "    'f1scores_emotions_flatten': 0.122,\n",
              "    'f1scores_triggers_instance': 0.4076,\n",
              "    'f1scores_triggers_flatten': 0.4321}}},\n",
              " 'model_BERT': {},\n",
              " 'model_BERT_Freezed': {}}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wTA_dWYFLlYb"
      },
      "outputs": [],
      "source": [
        "def init_pos_weight(data, labels, class_weights=True, factor=1):\n",
        "    if class_weights:\n",
        "        pos_weight = list()\n",
        "        emotions_counts = {label:0 for label in df_manager.unique_emotions}\n",
        "        for sentence_emotions in data[df_manager.column_emotions_id]:\n",
        "            for emotion in sentence_emotions:\n",
        "                emotions_counts[emotion] = emotions_counts[emotion] + 1\n",
        "        sum_of_all_emotions = sum(emotions_counts.values())\n",
        "        for label in labels:\n",
        "            w = (sum_of_all_emotions-emotions_counts[label])/emotions_counts[label]   # num_neg/num_pos for each class as specified in the documentation for BCEWithLogitsLoss\n",
        "            if w > 1:                       # increase recall of minority classes\n",
        "                w*=factor                   # factor to magnify the weight (not standard)\n",
        "                pos_weight.append(w)\n",
        "            else:\n",
        "                pos_weight.append(1)        # non minority classes are not influenced (pos_weight = 1)\n",
        "        return torch.tensor(pos_weight).to(\"cuda\")\n",
        "    else:\n",
        "        return torch.ones([len(labels)]).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ztKhP1pmLlYc"
      },
      "outputs": [],
      "source": [
        "class MultiLabelTrainer(Trainer):\n",
        "    def __init__(self, pos_weight, **kwargs):\n",
        "        self.pos_weight = pos_weight\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        emotions_true = inputs[\"emotions_id\"].to(\"cuda\")\n",
        "        triggers_true = inputs[\"triggers\"].float().unsqueeze(0).to(\"cuda\")\n",
        "        result = model(**inputs)\n",
        "        emotion_logits = result['emotion_logits'].to(\"cuda\")\n",
        "        trigger_logits = result['trigger_logits'].to(\"cuda\")\n",
        "        loss_fct_emotions = torch.nn.BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
        "        emotions_true_logits = torch.tensor(df_manager.unique_emotions_one_hot_encodings[emotions_true]).unsqueeze(0).to(\"cuda\")\n",
        "        loss_emotions = loss_fct_emotions(emotion_logits, emotions_true_logits)\n",
        "        loss_fct_triggers = torch.nn.BCEWithLogitsLoss()\n",
        "        loss_triggers = loss_fct_triggers(trigger_logits, triggers_true)\n",
        "        loss = loss_emotions + loss_triggers\n",
        "        return (loss, {'emotion_logits': emotion_logits, 'trigger_logits': trigger_logits}) if return_outputs else loss\n",
        "\n",
        "    #def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval):\n",
        "    #    # Your existing implementation\n",
        "    #    \n",
        "    #    # Print the contents of the metrics dictionary\n",
        "    #    print(\"Metrics dictionary:\", metrics)\n",
        "    #\n",
        "    #    # Your existing implementation\n",
        "\n",
        "def get_trainer(model, train, val, model_dir, class_weights=True, batch_size=1, epochs=20):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=model_dir,\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=0.01,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        lr_scheduler_type=\"cosine_with_restarts\",\n",
        "        save_total_limit = 1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='macro_avg_f1score',\n",
        "        report_to='none'\n",
        "    )\n",
        "    # pos_weight = init_pos_weight(concatenate_datasets([train_data_tokenized, val_data_tokenized, test_data_tokenized]), df_manager.emotion2id.keys(), class_weights)\n",
        "    pos_weight = init_pos_weight(concatenate_datasets([train_data_tokenized, val_data_tokenized, test_data_tokenized]), df_manager.emotion2id.keys(), False)\n",
        "    trainer = MultiLabelTrainer(\n",
        "        pos_weight=pos_weight,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train,\n",
        "        eval_dataset=val,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=lambda pred: compute_metrics(pred),\n",
        "    )\n",
        "\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y0haz8zYLlYc"
      },
      "outputs": [],
      "source": [
        "class BERT_Model(BertPreTrainedModel):\n",
        "    def __init__(self, load=None, pos_weight=None, freeze=False):\n",
        "        self.config = BertConfig.from_pretrained(model_card, output_attentions=True, output_hidden_states=True)\n",
        "        self.freeze = freeze\n",
        "\n",
        "        super().__init__(self.config)\n",
        "        self.core = self.initialize_model(load)\n",
        "        # Freeze BERT embedding layer parameters\n",
        "        if freeze:\n",
        "            for param in self.core.embeddings.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if pos_weight == None:\n",
        "            self.pos_weight = torch.ones([self.config.num_labels]).to(\"cuda\")\n",
        "        else:\n",
        "            self.pos_weight = pos_weight\n",
        "        self.emotion_head = nn.Linear(self.config.hidden_size, len(df_manager.unique_emotions))\n",
        "        self.trigger_head = nn.Linear(self.config.hidden_size, 1)\n",
        "        self.emotion_pooling = nn.AdaptiveMaxPool1d(7)\n",
        "        self.post_init()\n",
        "\n",
        "    def initialize_model(self, load):\n",
        "        if load == None:\n",
        "            return BertModel(self.config)\n",
        "        else:\n",
        "            print(\"load = \", load)\n",
        "            return BertModel.from_pretrained(load, config=load+'/config.json', local_files_only=True)\n",
        "        \n",
        "    def forward(\n",
        "        self,\n",
        "        concatenated_text_input_ids=None,\n",
        "        concatenated_text_attention_mask=None,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        emotions_id=None,\n",
        "        triggers=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "        outputs = self.core(\n",
        "            input_ids=concatenated_text_input_ids,\n",
        "            attention_mask=concatenated_text_attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = outputs.pooler_output.unsqueeze(1)\n",
        "        sentence_output = self.core(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        model_output = torch.cat((sequence_output, sentence_output.last_hidden_state), dim=1)\n",
        "        emotion_logits = torch.mean(self.emotion_head(model_output), dim=(1))\n",
        "        trigger_logits = torch.mean(self.trigger_head(model_output), dim=(1))\n",
        "        return {\"emotion_logits\": emotion_logits,\n",
        "                \"trigger_logits\": trigger_logits}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 7])\n",
            "torch.Size([2, 1])\n"
          ]
        }
      ],
      "source": [
        "model_B = BERT_Model()\n",
        "outputs_text = model_B(concatenated_text_input_ids=train_data_tokenized[0:2]['dialogue_ids'],\n",
        "        concatenated_text_attention_mask=train_data_tokenized[0:2]['dialogue_mask'],\n",
        "        input_ids=train_data_tokenized[0:2]['utterance_ids'],\n",
        "        attention_mask=train_data_tokenized[0:2]['utterance_mask'])\n",
        "\n",
        "print(outputs_text['emotion_logits'].shape)\n",
        "print(outputs_text['trigger_logits'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0FNnputQLlYc",
        "outputId": "a24d3ea2-5984-4c53-b455-c97f8224d9f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\datasets\\table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
            "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n",
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training BASE_MODEL with seed 666:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41f3bb768d854bccbaa3fc7d66fbae4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/280620 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['emotions_id', 'triggers']",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining BASE_MODEL with seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#trainer.evaluate(val_data_tokenized[0])\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1821\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1818\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1820\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1821\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   1822\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\data_loader.py:452\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 452\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\data\\data_collator.py:249\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m--> 249\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[0;32m    257\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3218\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[1;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[0;32m   3216\u001b[0m \u001b[38;5;66;03m# The model's main input name, usually `input_ids`, has be passed for padding\u001b[39;00m\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m encoded_inputs:\n\u001b[1;32m-> 3218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should supply an encoding or a list of encodings to this method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat includes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but you provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(encoded_inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3221\u001b[0m     )\n\u001b[0;32m   3223\u001b[0m required_input \u001b[38;5;241m=\u001b[39m encoded_inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m   3225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(required_input, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(required_input) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
            "\u001b[1;31mValueError\u001b[0m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['emotions_id', 'triggers']"
          ]
        }
      ],
      "source": [
        "seeds = [666]\n",
        "for seed in seeds:\n",
        "        set_seeds(seed)\n",
        "        base_model = BERT_Model()\n",
        "        # base_model_freezed = BERT_Model(freeze=True)\n",
        "\n",
        "        # Create trainer for Conclusion only\n",
        "        trainer = get_trainer(base_model, train_data_tokenized, val_data_tokenized, model_dir+\"baseline\", class_weights=True, batch_size=1, epochs=10)\n",
        "\n",
        "        # Create trainer for Conclusion+Premises\n",
        "        # trainer_freezed = get_trainer(base_model_freezed, train_dataset, val_dataset, model_dir+\"baseline_freezed\", class_weights=True, batch_size=1, epochs=10)\n",
        "        print(f'Training BASE_MODEL with seed {seed}:')\n",
        "        #trainer.evaluate(val_data_tokenized[0])\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        #print(f'Training BASE_MODEL_FREEZED with seed {seed}:')\n",
        "        #trainer_freezed.train()\n",
        "\n",
        "        #test_prediction_info = trainer.predict(dataset)\n",
        "        #test_predictions, test_labels = test_prediction_info.predictions, test_prediction_info.label_ids\n",
        "        #test_metrics.append(compute_metrics([test_predictions, test_labels], list(level_2.keys())))\n",
        "#\n",
        "        ## fill seed table\n",
        "        #seed_table[\"model_BERT\"][seed] = test_bert\n",
        "        #seed_table[\"model_BERT_Freezed\"][seed] = test_CP"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
