{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install transformers[torch]\n",
        "# !pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tb6JkaXPQ8c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\marco\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch\n",
        "import urllib\n",
        "from src.utils import *\n",
        "from src.models.baseline import Baseline\n",
        "from torch import nn\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import f1_score, multilabel_confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, concatenate_datasets\n",
        "from tqdm import tqdm\n",
        "from transformers import BertLayer, AutoModelForSequenceClassification, DefaultDataCollator, AutoTokenizer, AutoConfig, TrainingArguments, Trainer, BertConfig, BertModel, BertPreTrainedModel, RobertaConfig, RobertaModel;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2MsBHCqQ8c_",
        "outputId": "4940d008-c6d5-494c-907a-8198446a460b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.0+cu121\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "RANDOM_SEED = 42\n",
        "set_seeds(RANDOM_SEED)\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current work directory: c:\\Users\\marco\\OneDrive\\Immagini\\Documenti\\GitHub\\ediref\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>emotions</th>\n",
              "      <th>utterances</th>\n",
              "      <th>triggers</th>\n",
              "      <th>emotions_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 1, 0]</td>\n",
              "      <td>[3, 3, 3, 3, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utterance_1</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[3, 3, 3, 3, 5, 3, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utterance_2</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "      <td>[3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utterance_3</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 2, 3, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utterance_4</td>\n",
              "      <td>[surprise, sadness, surprise, fear]</td>\n",
              "      <td>[But then who? The waitress I went out with la...</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[5, 6, 5, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>utterance_3995</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>[3, 1, 3, 3, 5, 0, 3, 0, 5, 3, 3, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>utterance_3996</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>[3, 1, 3, 3, 5, 0, 3, 0, 5, 3, 3, 0, 0, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>utterance_3997</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[3, 1, 3, 3, 5, 0, 3, 0, 5, 3, 3, 0, 0, 3, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>utterance_3998</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[3, 1, 3, 3, 5, 0, 3, 0, 5, 3, 3, 0, 0, 3, 3, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>utterance_3999</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[3, 1, 3, 3, 5, 0, 3, 0, 5, 3, 3, 0, 0, 3, 3, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             episode                                           emotions  \\\n",
              "0        utterance_0     [neutral, neutral, neutral, neutral, surprise]   \n",
              "1        utterance_1  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "2        utterance_2  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "3        utterance_3  [neutral, neutral, neutral, neutral, surprise,...   \n",
              "4        utterance_4                [surprise, sadness, surprise, fear]   \n",
              "...              ...                                                ...   \n",
              "3995  utterance_3995  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3996  utterance_3996  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3997  utterance_3997  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3998  utterance_3998  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3999  utterance_3999  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "\n",
              "                                             utterances  \\\n",
              "0     [also I was the point person on my company's t...   \n",
              "1     [also I was the point person on my company's t...   \n",
              "2     [also I was the point person on my company's t...   \n",
              "3     [also I was the point person on my company's t...   \n",
              "4     [But then who? The waitress I went out with la...   \n",
              "...                                                 ...   \n",
              "3995  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3996  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3997  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3998  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3999  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "\n",
              "                                               triggers  \\\n",
              "0                                       [0, 0, 0, 1, 0]   \n",
              "1                                 [0, 0, 0, 0, 0, 1, 0]   \n",
              "2                     [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
              "3               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
              "4                                          [0, 0, 1, 0]   \n",
              "...                                                 ...   \n",
              "3995               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
              "3996         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
              "3997      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
              "3998   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
              "3999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                            emotions_id  \n",
              "0                                       [3, 3, 3, 3, 5]  \n",
              "1                                 [3, 3, 3, 3, 5, 3, 3]  \n",
              "2                     [3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 2]  \n",
              "3               [3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 2, 3, 5]  \n",
              "4                                          [5, 6, 5, 2]  \n",
              "...                                                 ...  \n",
              "3995               [3, 1, 3, 3, 5, 0, 3, 0, 5, 3, 3, 0]  \n",
              "3996         [3, 1, 3, 3, 5, 0, 3, 0, 5, 3, 3, 0, 0, 3]  \n",
              "3997      [3, 1, 3, 3, 5, 0, 3, 0, 5, 3, 3, 0, 0, 3, 3]  \n",
              "3998   [3, 1, 3, 3, 5, 0, 3, 0, 5, 3, 3, 0, 0, 3, 3, 5]  \n",
              "3999  [3, 1, 3, 3, 5, 0, 3, 0, 5, 3, 3, 0, 0, 3, 3, ...  \n",
              "\n",
              "[4000 rows x 5 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = \"https://drive.google.com/uc?export=download&id=1wVNU2XvvhqjaGXZM-JLJwOt97gt4g9j2\"\n",
        "dataset_name = \"MELD_train_efr.json\"\n",
        "\n",
        "df_manager = DataframeManager(url, dataset_name)\n",
        "\n",
        "df = df_manager.produce_df()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aYeINdxlLlYW",
        "outputId": "08317111-0a25-4b78-eac1-f6609fa7ee4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3200, 5)\n",
            "(400, 5)\n",
            "(400, 5)\n"
          ]
        }
      ],
      "source": [
        "train_df, val_df, test_df = df_manager.split_df(RANDOM_SEED)\n",
        "print(train_df.shape)\n",
        "print(val_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "9TNd9SBUa60R",
        "outputId": "1ee58b4f-f7be-4347-8798-26bdcc1dd36c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_manager.plot_emotion_distribution(train_df, val_df, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kOwxAe3qLlYZ"
      },
      "outputs": [],
      "source": [
        "model_card = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
        "\n",
        "model_dir = \"./model_dir/\"+model_card+\"/\"\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-UN6VqNKQ8dR",
        "outputId": "327af93c-801b-40fc-e9fc-49c93fad93ad"
      },
      "outputs": [],
      "source": [
        "train_data_tokenized, val_data_tokenized, test_data_tokenized = df_manager.produce_dataset(tokenizer, RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m num_el \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataset\u001b[49m:\n\u001b[0;32m      3\u001b[0m     num_el \u001b[38;5;241m=\u001b[39m num_el \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(el[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutterances\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(num_el)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "# num_el = 0\n",
        "# for el in train_dataset:\n",
        "#     num_el = num_el + len(el['utterances'])\n",
        "# print(num_el)\n",
        "# num_el = 0\n",
        "# for el in val_dataset:\n",
        "#     num_el = num_el + len(el['utterances'])\n",
        "# print(num_el)\n",
        "# num_el = 0\n",
        "# for el in test_dataset:\n",
        "#     num_el = num_el + len(el['utterances'])\n",
        "# print(num_el)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJWSxdXFQ8dT"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OSNzNVyiLlYb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "compute_metrics was called\n",
            "compute_metrics was called\n",
            "compute_metrics was called\n",
            "compute_metrics was called\n",
            "compute_metrics was called\n",
            "compute_metrics was called\n"
          ]
        }
      ],
      "source": [
        "seeds = [666, 55, 42]\n",
        "\n",
        "X = train_df['utterances']\n",
        "Y = train_df[['triggers', 'emotions_id']]\n",
        "seed_table = {'majority': {}, 'uniform': {},\n",
        "              'model_BERT': {}, 'model_BERT_Freezed': {}}\n",
        "\n",
        "id2emotion = df_manager.get_id2emotion()\n",
        "random_clf = Baseline(\"uniform\", X, Y, id2emotion)\n",
        "majority_clf = Baseline(\"most_frequent\", X, Y, id2emotion)\n",
        "for seed in seeds:\n",
        "    seed_table[\"uniform\"][seed] = random_clf.score()\n",
        "    seed_table[\"majority\"][seed] = majority_clf.score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx520nvqLlYb",
        "outputId": "6c7d3294-88ee-44a5-c995-22a56d17676b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'majority': {666: {'accuracy': 0.6403,\n",
              "   'f1-score': {'accuracy_emotions': 0.4392,\n",
              "    'accuracy_triggers': 0.8415,\n",
              "    'f1scores_emotions_instance': 0.0814,\n",
              "    'f1scores_emotions_flatten': 0.0872,\n",
              "    'f1scores_triggers_instance': 0.4392,\n",
              "    'f1scores_triggers_flatten': 0.457}},\n",
              "  55: {'accuracy': 0.6403,\n",
              "   'f1-score': {'accuracy_emotions': 0.4392,\n",
              "    'accuracy_triggers': 0.8415,\n",
              "    'f1scores_emotions_instance': 0.0814,\n",
              "    'f1scores_emotions_flatten': 0.0872,\n",
              "    'f1scores_triggers_instance': 0.4392,\n",
              "    'f1scores_triggers_flatten': 0.457}},\n",
              "  42: {'accuracy': 0.6403,\n",
              "   'f1-score': {'accuracy_emotions': 0.4392,\n",
              "    'accuracy_triggers': 0.8415,\n",
              "    'f1scores_emotions_instance': 0.0814,\n",
              "    'f1scores_emotions_flatten': 0.0872,\n",
              "    'f1scores_triggers_instance': 0.4392,\n",
              "    'f1scores_triggers_flatten': 0.457}}},\n",
              " 'uniform': {666: {'accuracy': 0.3197,\n",
              "   'f1-score': {'accuracy_emotions': 0.1458,\n",
              "    'accuracy_triggers': 0.5006,\n",
              "    'f1scores_emotions_instance': 0.0734,\n",
              "    'f1scores_emotions_flatten': 0.1225,\n",
              "    'f1scores_triggers_instance': 0.4092,\n",
              "    'f1scores_triggers_flatten': 0.4348}},\n",
              "  55: {'accuracy': 0.3203,\n",
              "   'f1-score': {'accuracy_emotions': 0.143,\n",
              "    'accuracy_triggers': 0.5036,\n",
              "    'f1scores_emotions_instance': 0.0724,\n",
              "    'f1scores_emotions_flatten': 0.1197,\n",
              "    'f1scores_triggers_instance': 0.4126,\n",
              "    'f1scores_triggers_flatten': 0.4367}},\n",
              "  42: {'accuracy': 0.321,\n",
              "   'f1-score': {'accuracy_emotions': 0.1445,\n",
              "    'accuracy_triggers': 0.4971,\n",
              "    'f1scores_emotions_instance': 0.0724,\n",
              "    'f1scores_emotions_flatten': 0.122,\n",
              "    'f1scores_triggers_instance': 0.4076,\n",
              "    'f1scores_triggers_flatten': 0.4321}}},\n",
              " 'model_BERT': {},\n",
              " 'model_BERT_Freezed': {}}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wTA_dWYFLlYb"
      },
      "outputs": [],
      "source": [
        "def init_pos_weight(data, labels, class_weights=True, factor=1):\n",
        "    if class_weights:\n",
        "        pos_weight = list()\n",
        "        emotions_counts = {label:0 for label in df_manager.unique_emotions}\n",
        "        for sentence_emotions in data[df_manager.column_emotions_id]:\n",
        "            for emotion in sentence_emotions:\n",
        "                emotions_counts[emotion] = emotions_counts[emotion] + 1\n",
        "        sum_of_all_emotions = sum(emotions_counts.values())\n",
        "        for label in labels:\n",
        "            w = (sum_of_all_emotions-emotions_counts[label])/emotions_counts[label]   # num_neg/num_pos for each class as specified in the documentation for BCEWithLogitsLoss\n",
        "            if w > 1:                       # increase recall of minority classes\n",
        "                w*=factor                   # factor to magnify the weight (not standard)\n",
        "                pos_weight.append(w)\n",
        "            else:\n",
        "                pos_weight.append(1)        # non minority classes are not influenced (pos_weight = 1)\n",
        "        return torch.tensor(pos_weight).to(\"cuda\")\n",
        "    else:\n",
        "        return torch.ones([len(labels)]).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ztKhP1pmLlYc"
      },
      "outputs": [],
      "source": [
        "class MultiLabelTrainer(Trainer):\n",
        "    def __init__(self, pos_weight, **kwargs):\n",
        "        self.pos_weight = pos_weight\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        emotions_true = inputs[\"emotions_id\"].to(\"cuda\")\n",
        "        triggers_true = inputs[\"triggers\"].float().unsqueeze(0).to(\"cuda\")\n",
        "\n",
        "        result = model(**inputs)\n",
        "        \n",
        "        emotion_logits = result['emotion_logits'].to(\"cuda\")\n",
        "        trigger_logits = result['trigger_logits'].to(\"cuda\")\n",
        "        \n",
        "        loss_fct_emotions = torch.nn.BCEWithLogitsLoss(pos_weight=self.pos_weight)        \n",
        "        loss_fct_triggers = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "        loss_triggers = loss_fct_triggers(trigger_logits, triggers_true)\n",
        "        loss_emotions = loss_fct_emotions(emotion_logits, emotions_true.float())\n",
        "\n",
        "        loss = loss_emotions + loss_triggers\n",
        "        return (loss, {'emotion_logits': emotion_logits, 'trigger_logits': trigger_logits}) if return_outputs else loss\n",
        "\n",
        "    #def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval):\n",
        "    #    # Your existing implementation\n",
        "    #    \n",
        "    #    # Print the contents of the metrics dictionary\n",
        "    #    print(\"Metrics dictionary:\", metrics)\n",
        "    #\n",
        "    #    # Your existing implementation\n",
        "\n",
        "def get_trainer(model, train, val, model_dir, class_weights=True, batch_size=1, epochs=20):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=model_dir,\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=0.01,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        lr_scheduler_type=\"cosine_with_restarts\",\n",
        "        save_total_limit = 1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='macro_avg_f1score',\n",
        "        report_to='none'\n",
        "    )\n",
        "    # pos_weight = init_pos_weight(concatenate_datasets([train_data_tokenized, val_data_tokenized, test_data_tokenized]), df_manager.emotion2id.keys(), class_weights)\n",
        "    pos_weight = init_pos_weight(concatenate_datasets([train_data_tokenized, val_data_tokenized, test_data_tokenized]), df_manager.emotion2id.keys(), False)\n",
        "    trainer = MultiLabelTrainer(\n",
        "        pos_weight=pos_weight,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train,\n",
        "        eval_dataset=val,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=lambda pred: compute_metrics(pred),\n",
        "    )\n",
        "\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y0haz8zYLlYc"
      },
      "outputs": [],
      "source": [
        "class BERT_Model(BertPreTrainedModel):\n",
        "    def __init__(self, load=None, pos_weight=None, freeze=False):\n",
        "        self.config = BertConfig.from_pretrained(model_card, output_attentions=True, output_hidden_states=True)\n",
        "        self.freeze = freeze\n",
        "\n",
        "        super().__init__(self.config)\n",
        "        self.core = self.initialize_model(load)\n",
        "        # Freeze BERT embedding layer parameters\n",
        "        if freeze:\n",
        "            for param in self.core.embeddings.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if pos_weight == None:\n",
        "            self.pos_weight = torch.ones([self.config.num_labels]).to(\"cuda\")\n",
        "        else:\n",
        "            self.pos_weight = pos_weight\n",
        "        self.emotion_head = nn.Linear(self.config.hidden_size, len(df_manager.unique_emotions))\n",
        "        self.trigger_head = nn.Linear(self.config.hidden_size, 1)\n",
        "        self.emotion_pooling = nn.AdaptiveMaxPool1d(7)\n",
        "        self.post_init()\n",
        "\n",
        "    def initialize_model(self, load):\n",
        "        if load == None:\n",
        "            return BertModel(self.config)\n",
        "        else:\n",
        "            print(\"load = \", load)\n",
        "            return BertModel.from_pretrained(load, config=load+'/config.json', local_files_only=True)\n",
        "        \n",
        "    def forward(\n",
        "        self,\n",
        "        utterance_ids=None,\n",
        "        utterance_mask=None,\n",
        "        dialogue_ids=None,\n",
        "        dialogue_mask=None,\n",
        "        token_type_ids=None,\n",
        "        emotions_id=None,\n",
        "        triggers=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "        outputs = self.core(\n",
        "            input_ids=dialogue_ids,\n",
        "            attention_mask=dialogue_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = outputs.pooler_output.unsqueeze(1)\n",
        "        sentence_output = self.core(\n",
        "            input_ids=utterance_ids,\n",
        "            attention_mask=utterance_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        model_output = torch.cat((sequence_output, sentence_output.last_hidden_state), dim=1)\n",
        "        emotion_logits = torch.mean(self.emotion_head(model_output), dim=(1))\n",
        "        trigger_logits = torch.mean(self.trigger_head(model_output), dim=(1))\n",
        "        return {\"emotion_logits\": emotion_logits,\n",
        "                \"trigger_logits\": trigger_logits}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 7])\n",
            "torch.Size([2, 1])\n"
          ]
        }
      ],
      "source": [
        "model_B = BERT_Model()\n",
        "outputs_text = model_B(concatenated_text_input_ids=train_data_tokenized[0:2]['dialogue_ids'],\n",
        "        concatenated_text_attention_mask=train_data_tokenized[0:2]['dialogue_mask'],\n",
        "        input_ids=train_data_tokenized[0:2]['utterance_ids'],\n",
        "        attention_mask=train_data_tokenized[0:2]['utterance_mask'])\n",
        "\n",
        "print(outputs_text['emotion_logits'].shape)\n",
        "print(outputs_text['trigger_logits'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data_tokenized[85][\"dialogue_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'emotions_id': tensor([1, 0, 0, 0, 0, 0, 0]),\n",
              " 'triggers': tensor(0),\n",
              " 'input_ids': tensor([  101,  2298,  1010,  1045,  2514,  2428,  2919,  2055,  2129,  1045,\n",
              "         22783,  2017,  2041,  2077,  1010,  2061,  1045,  2170,  1996,  2269,\n",
              "          1998,  2356,  2032,  2000,  3113,  2017,  2182,  2061,  2017,  2064,\n",
              "          2425,  2032,  1012,   102,  2175,   999,   102]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'dialogue_text': 'Look, I feel really bad about how I freaked you out before, so I called the father and asked him to meet you here so you can tell him. [SEP] Go!',\n",
              " 'utterance_ids': tensor([  101,  2298,  1010,  1045,  2514,  2428,  2919,  2055,  2129,  1045,\n",
              "         22783,  2017,  2041,  2077,  1010,  2061,  1045,  2170,  1996,  2269,\n",
              "          1998,  2356,  2032,  2000,  3113,  2017,  2182,  2061,  2017,  2064,\n",
              "          2425,  2032,  1012,   102]),\n",
              " 'utterance_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_tokenized[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0FNnputQLlYc",
        "outputId": "a24d3ea2-5984-4c53-b455-c97f8224d9f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\datasets\\table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
            "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n",
            "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training BASE_MODEL with seed 666:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abd3a6321fe34928aefdf5dc7df5bcd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/280620 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.2196, 'learning_rate': 1.9999843335216157e-05, 'epoch': 0.02}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6644a400a885408bbe69a2df80cb133d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3437 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining BASE_MODEL with seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#trainer.evaluate(val_data_tokenized[0])\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1914\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1911\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[0;32m   1912\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 1914\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1916\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:2263\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2261\u001b[0m         metrics\u001b[38;5;241m.\u001b[39mupdate(dataset_metrics)\n\u001b[0;32m   2262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2263\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2266\u001b[0m \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:3007\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3004\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3006\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3007\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3008\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3010\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   3011\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   3012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3015\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3017\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   3018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:3221\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3220\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n\u001b[1;32m-> 3221\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3222\u001b[0m     preds_host \u001b[38;5;241m=\u001b[39m logits \u001b[38;5;28;01mif\u001b[39;00m preds_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m nested_concat(preds_host, logits, padding_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m   3224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\accelerator.py:2254\u001b[0m, in \u001b[0;36mAccelerator.gather_for_metrics\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m   2252\u001b[0m     data \u001b[38;5;241m=\u001b[39m gather_object(input_data)\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2254\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2256\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mend_of_dataloader:\n\u001b[0;32m   2258\u001b[0m         \u001b[38;5;66;03m# at the end of a dataloader, `gather_for_metrics` regresses to\u001b[39;00m\n\u001b[0;32m   2259\u001b[0m         \u001b[38;5;66;03m# `gather` unless the dataset has a remainder so log.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\accelerator.py:2217\u001b[0m, in \u001b[0;36mAccelerator.gather\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m   2187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgather\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor):\n\u001b[0;32m   2188\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;124;03m    Gather the values in *tensor* across all processes and concatenate them on the first dimension. Useful to\u001b[39;00m\n\u001b[0;32m   2190\u001b[0m \u001b[38;5;124;03m    regroup the predictions from all processes when doing evaluation.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2215\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m   2216\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\utils\\operations.py:381\u001b[0m, in \u001b[0;36mverify_operation.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m PartialState()\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mNO \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m PartialState()\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m--> 381\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    382\u001b[0m     operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\utils\\operations.py:441\u001b[0m, in \u001b[0;36mgather\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PartialState()\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tpu_gather(tensor)\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mPartialState\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;129;01min\u001b[39;00m TORCH_DISTRIBUTED_OPERATION_TYPES:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _gpu_gather(tensor)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\state.py:290\u001b[0m, in \u001b[0;36mPartialState.__init__\u001b[1;34m(self, cpu, **kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfork_launched \u001b[38;5;241m=\u001b[39m parse_flag_from_env(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFORK_LAUNCHED\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# Check for old RTX 4000's that can't use P2P or IB and are on old drivers\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcheck_cuda_p2p_ib_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNCCL_P2P_DISABLE\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNCCL_IB_DISABLE\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing RTX 4000 series doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support faster communication broadband via P2P or IB. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease set `NCCL_P2P_DISABLE=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` and `NCCL_IB_DISABLE=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or use `accelerate launch` which \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    295\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill do this automatically.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    296\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\utils\\environment.py:154\u001b[0m, in \u001b[0;36mcheck_cuda_p2p_ib_support\u001b[1;34m()\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03mChecks if the devices being used have issues with P2P and IB communications, namely any consumer GPU hardware after\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mthe 3090.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03mNoteably uses `nvidia-smi` instead of torch to not initialize CUDA.\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     device_names, device_count \u001b[38;5;241m=\u001b[39m \u001b[43mget_gpu_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# As new consumer GPUs get released, add them to `unsupported_devices``\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     unsupported_devices \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRTX 40\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\accelerate\\utils\\environment.py:122\u001b[0m, in \u001b[0;36mget_gpu_info\u001b[1;34m()\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03mGets GPU count and names using `nvidia-smi` instead of torch to not initialize CUDA.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03mLargely based on the `gputil` library.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Returns as list of `n` GPUs and their names\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m_nvidia_smi\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--query-gpu=count,name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--format=csv,noheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniversal_newlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    126\u001b[0m gpus \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplit(os\u001b[38;5;241m.\u001b[39mlinesep)\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\subprocess.py:424\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    422\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[1;32m--> 424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run(\u001b[38;5;241m*\u001b[39mpopenargs, stdout\u001b[38;5;241m=\u001b[39mPIPE, timeout\u001b[38;5;241m=\u001b[39mtimeout, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    425\u001b[0m            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mstdout\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\subprocess.py:507\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    509\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\subprocess.py:1121\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stdin_write(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout:\n\u001b[1;32m-> 1121\u001b[0m     stdout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr:\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\encodings\\cp1252.py:22\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalDecoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalDecoder):\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,decoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1363\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1664\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydev_bundle\\pydev_is_thread_alive.py:9\u001b[0m, in \u001b[0;36mis_thread_alive\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m      6\u001b[0m _temp \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mThread()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_temp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_stopped\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Python 3.x has this\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_thread_alive\u001b[39m(t):\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39m_is_stopped\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_temp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Thread__stopped\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Python 2.x has this\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "seeds = [666]\n",
        "for seed in seeds:\n",
        "        set_seeds(seed)\n",
        "        base_model = BERT_Model()\n",
        "        # base_model_freezed = BERT_Model(freeze=True)\n",
        "\n",
        "        # Create trainer for Conclusion only\n",
        "        trainer = get_trainer(base_model, train_data_tokenized, val_data_tokenized, model_dir+\"baseline\", class_weights=True, batch_size=1, epochs=10)\n",
        "\n",
        "        # Create trainer for Conclusion+Premises\n",
        "        # trainer_freezed = get_trainer(base_model_freezed, train_dataset, val_dataset, model_dir+\"baseline_freezed\", class_weights=True, batch_size=1, epochs=10)\n",
        "        print(f'Training BASE_MODEL with seed {seed}:')\n",
        "        #trainer.evaluate(val_data_tokenized[0])\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        #print(f'Training BASE_MODEL_FREEZED with seed {seed}:')\n",
        "        #trainer_freezed.train()\n",
        "\n",
        "        #test_prediction_info = trainer.predict(dataset)\n",
        "        #test_predictions, test_labels = test_prediction_info.predictions, test_prediction_info.label_ids\n",
        "        #test_metrics.append(compute_metrics([test_predictions, test_labels], list(level_2.keys())))\n",
        "#\n",
        "        ## fill seed table\n",
        "        #seed_table[\"model_BERT\"][seed] = test_bert\n",
        "        #seed_table[\"model_BERT_Freezed\"][seed] = test_CP"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
